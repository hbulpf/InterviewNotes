(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{383:function(t,s,e){"use strict";e.r(s);var n=e(42),o=Object(n.a)({},(function(){var t=this.$createElement,s=this._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[s("ol",[s("li",[s("p",[this._v("一台8G内存/500G磁盘空间的普通电脑，如何对一个100G的大文件进行排序？假定文件中都是字符串记录，一行约100个字符。")]),this._v(" "),s("blockquote",[s("p",[this._v("这是一个典型的分治问题，100G的大文件肯定无法一次加载到内存直接排序，所以需要先切分成若干小问题来解决。那么8G内存的计算机一次大概能排多大的数据量，可以在有限的时间内排完呢？也就是100G的大文件要怎么切法，切成多少份比较合适？这个是考察候选人的时间空间复杂度估算能力，需要一定的计算机组织和算法功底，也需要一定实战经验和sense。实际上8G内存的话，操作系统要用掉一部分，如果用Java开发排序程序，大致JVM可用2~4G内存，基于一般的经验值，一次排1G左右的数据应该没有问题（我实际在计算机上干过1G数据的排序，是OK的）。所以100G的文件需要先切分成100份，每份1G，这样每个子文件可以直接加载到内存进行排序。对于1G数据量的字符串排序，采用Java里头提供的快速排序算法是比较合适的。")])])])]),this._v(" "),s("blockquote",[s("p",[this._v("经过有限时间的排序（取决于计算机性能，快的一天内能排完），假定100个1G的文件都已经排好了，相当于现在硬盘上有100个已经排好序的文件，但是我们最终需要的是一个排好序的文件，下面该怎么做？这个时候我们需要把已经解决的子问题组合起来，合并成我们需要的最终结果文件。这个时候该采用什么算法呢？这里考察候选人对外排序和归并排序算法的掌握程度，我们可以将100个排好序的文件进行两两归并排序，这样不断重复，我们就会得到50个排好序的文件，每个大小是2G。然后再两两归并，不断重复，直到最后两个文件归并成目标文件，这个文件就是100G并且是排好序的。因为是外排序+归并排序，每次只需要读取当前索引指向的文件记录到内存，进行比较，小的那个输出到目标文件，内存占用极少。另外，上面的算法是两路归并，也可以采用多路归并，甚至是采用堆排序进行优化，但是总体分治思路没有变化。")])])])}),[],!1,null,null,null);s.default=o.exports}}]);